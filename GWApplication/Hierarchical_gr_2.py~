## Issues for discussion :
# 2. the proportionality constant of measurement error
# 3. region of integration
from numpy import random as rand
from matplotlib import pyplot as plt
from scipy.integrate import quad
import numpy as np
pi = np.pi

def init_plotting():
    
    plt.rcParams['figure.max_open_warning'] = 0
    
    plt.rcParams['mathtext.fontset']  = 'stix'
    plt.rcParams['font.family']       = 'STIXGeneral'

    plt.rcParams['font.size']         = 10
    plt.rcParams['axes.linewidth']    = 1
    plt.rcParams['axes.labelsize']    = plt.rcParams['font.size']
    plt.rcParams['axes.titlesize']    = 1.5*plt.rcParams['font.size']
    plt.rcParams['legend.fontsize']   = plt.rcParams['font.size']
    plt.rcParams['xtick.labelsize']   = plt.rcParams['font.size']
    plt.rcParams['ytick.labelsize']   = plt.rcParams['font.size']
    plt.rcParams['xtick.major.size']  = 3
    plt.rcParams['xtick.minor.size']  = 3
    plt.rcParams['xtick.major.width'] = 1
    plt.rcParams['xtick.minor.width'] = 1
    plt.rcParams['ytick.major.size']  = 3
    plt.rcParams['ytick.minor.size']  = 3
    plt.rcParams['ytick.major.width'] = 1
    plt.rcParams['ytick.minor.width'] = 1
    
    plt.rcParams['legend.frameon']             = False
    plt.rcParams['legend.loc']                 = 'center left'
    plt.rcParams['contour.negative_linestyle'] = 'solid'
    
    plt.gca().spines['right'].set_color('none')
    plt.gca().spines['top'].set_color('none')
    plt.gca().xaxis.set_ticks_position('bottom')
    plt.gca().yaxis.set_ticks_position('left')
    
    return

def SNR(x):
    '''
    the Signal to Noise ratio
    probability disribution
    '''
    return 1/x**4

def inverse_cdf_SNR(x):
    return -(1/(3*x))**(1/3)

def gaussian(p, mu, sigma):
    expo = -0.5*( (p - mu)/sigma )**2
    norm = 1/np.sqrt(2*pi*sigma**2)
    return norm*np.exp(expo)

init_plotting()

n_data = 100
u = np.array( [ rand.uniform(0,1,n_data) for i in range(3)] )
sampled_SNR = np.array( [ abs( inverse_cdf_SNR(u_i) ) for u_i in u ] ) # a threshold of SNR =12
plt.hist(sampled_SNR)
plt.show()
exit()

#print(sampled_SNR[0])
#prop = 24*0.06, 0.3, 0.2
measurement_error_0 = (1/sampled_SNR[0])*rand.normal(1, 0.03, n_data)
measurement_error_1 = (1/sampled_SNR[1])*rand.normal(1, 0.15, n_data)
measurement_error_2 = (1/sampled_SNR[2])*rand.normal(1, 0.1, n_data)

dpi_0 = 1.1 - 2*rand.uniform(0.1,1,n_data)

deltaPhi_0 = np.array(
    [rand.normal(dpi_0[i], abs(measurement_error_0[i])) for i in range(n_data)]
)

deltaPhi_1 = np.array(
    [rand.normal(0., abs(m_e)) for m_e in measurement_error_1]
)
deltaPhi_2 = np.array(
    [rand.normal(0.2, abs(m_e)) for m_e in measurement_error_2]
)


def integral(mu_j, sigma_j, measured_param, measurement_error, n_data, prior_mu, prior_s):
    integrals = [
        quad( lambda p_i: gaussian(p_i, measured_param[i], measurement_error[i])*gaussian(p_i, mu_j, sigma_j),
              measured_param[i]-3*measurement_error[i], measured_param[i]+3*measurement_error[i])[0]
        for i in range(n_data) # the limit of integration is 3sigma around each p_i
    ]
    result = 1
    for i in integrals:
        result *= i
        
    return prior_mu*prior_s*result

prior_mu_0 = 1/0.1 # the hyper prior on the hyper mu as taken from the graph
prior_s_0 = 1/0.09 # the hyper prior on the hyper sigma as taken from the graph

prior_mu_1 = 1/0.1 # the hyper prior on the hyper mu as taken from the graph
prior_s_1 = 1/0.09 # the hyper prior on the hyper sigma as taken from the graph

prior_mu_2 = 1/0.1 # the hyper prior on the hyper mu as taken from the graph
prior_s_2 = 1/0.09 # the hyper prior on the hyper sigma as taken from the graph

hyper_mus_0, hyper_sigmas_0 = list(), list()
mu_acc, s_acc = 0, 1
n_samples= 1
for i in range(5000):
    mu_new= rand.normal(mu_acc, 1)
    s_new= rand.normal(s_acc, 0.01)
    p = integral(mu_new,s_new, deltaPhi_0, measurement_error_0, n_data, prior_mu_0, prior_s_0)\
        /integral(mu_acc, s_acc, deltaPhi_0, measurement_error_0, n_data, prior_mu_0, prior_s_0) 
    #
    T = min(1, p)
    u = rand.random_sample()
    if u <= T:
        mu_acc, s_acc = mu_new, s_new
        n_samples += 1
    hyper_mus_0.append(mu_acc)
    hyper_sigmas_0.append(s_acc)
    print('Acceptance: {perc} ({samples_N}/{tot_N})'.format(perc=(n_samples/(i+1)), samples_N=n_samples, tot_N=i+1))
    #
#
hyper_mus_1, hyper_sigmas_1 = list(), list()
mu_acc, s_acc = 0, 1
n_samples= 1
for i in range(5000):
    mu_new= rand.normal(mu_acc, 1)
    s_new= rand.normal(s_acc, 0.01)
    p = integral(mu_new,s_new, deltaPhi_1, measurement_error_1, n_data, prior_mu_1, prior_s_1)\
        /integral(mu_acc, s_acc, deltaPhi_1, measurement_error_1, n_data, prior_mu_1, prior_s_1) 
    #
    T = min(1, p)
    u = rand.random_sample()
    if u <= T:
        mu_acc, s_acc = mu_new, s_new
        n_samples += 1
    hyper_mus_1.append(mu_acc)
    hyper_sigmas_1.append(s_acc)
    print('Acceptance: {perc} ({samples_N}/{tot_N})'.format(perc=(n_samples/(i+1)), samples_N=n_samples, tot_N=i+1))
 #
hyper_mus_2, hyper_sigmas_2 = list(), list()
mu_acc, s_acc = 0, 1
n_samples= 1
for i in range(5000):
    mu_new= rand.normal(mu_acc, 1)
    s_new= rand.normal(s_acc, 0.01)
    p = integral(mu_new,s_new, deltaPhi_2, measurement_error_2, n_data, prior_mu_2, prior_s_2)\
        /integral(mu_acc, s_acc, deltaPhi_2, measurement_error_2, n_data, prior_mu_2, prior_s_2) 
    #
    T = min(1, p)
    u = rand.random_sample()
    if u <= T:
        mu_acc, s_acc = mu_new, s_new
        n_samples += 1
    hyper_mus_2.append(mu_acc)
    hyper_sigmas_2.append(s_acc)
    print('Acceptance: {perc} ({samples_N}/{tot_N})'.format(perc=(n_samples/(i+1)), samples_N=n_samples, tot_N=i+1))
# 

plt.hist(hyper_mus_0,50, alpha=0.5, density=True, label=r'$\delta\hat\phi_0$')
plt.hist(hyper_mus_1,50, alpha=0.5, density=True, label=r'$\delta\hat\phi_1$')
plt.hist(hyper_mus_2,50, alpha=0.5, density=True, label=r'$\delta\hat\phi_2$')
plt.xlim(-0.3, 0.3)
plt.ylim(0, 10)
plt.xlabel(r'$\mu$')
plt.ylabel(r'$\int d\sigma P(\mu, \sigma|D)$')
plt.legend(loc='best')

plt.figure()
plt.hist(hyper_sigmas_0, alpha=0.5, density=True, label=r'$\delta\hat\phi_0$')
plt.hist(hyper_sigmas_1, alpha=0.5, density=True, label=r'$\delta\hat\phi_1$')
plt.hist(hyper_sigmas_2, alpha=0.5, density=True, label=r'$\delta\hat\phi_2$')
plt.xlim(0., 0.8)
plt.xlabel(r'$\sigma$')
plt.ylabel(r'$\int d\mu P(\mu, \sigma|D)$')
plt.legend(loc='best')
plt.show()
#f1 = lambda p_i: gaussian(p_i, measured_param, measurement_error)#*gaussian(p_i, mu_j, sigma_j) 

#test = quad(f1, 


'''
s0 = 0.5 # the initial position
s_acc = s0 #accepted
k = 0
sampled_SNR = list()
n_samples = 1
while lenampled_SNR) != 100:
    k+=1
    s_new = rand.standard_cauchy() 
    p = SNR(s_new)/SNR(s_acc) 
    T = min(1, p)
    u = rand.random_sample()
    if u <= T:
        s_acc = s_new
        n_samples += 1
    sampled_SNR.append(s_acc)
    print('Acceptance: {perc} ({samples_N}/{tot_N})'\
          .format(perc=(n_samples/(k+1)), samples_N=n_samples, tot_N=k+1))

    #
#
sampled_SNR = np.array(sampled_SNR)
'''
